# Tokenizer 

## Description

A tokenizer is a program that takes a string of text and breaks it up into individual tokens. These tokens can be words, phrases, or even individual characters.

Minimal spec 

```python
import re

def tokenize(text):
    # Replace all non-alphanumeric characters with a space
    text = re.sub(r'\W+', ' ', text)

    # Convert to lowercase and split on whitespace
    tokens = text.lower().split()

    return tokens

```

Type of obect 

BPE 


Descentralized

convert the merge indices to RLP-encoded bytes before encoding the input text


Tamper proof of X policy cost
```python
import rlp
from collections import defaultdict

class BPEncoder:
    def __init__(self, num_merges=100):
        self.num_merges = num_merges
        self.vocab = defaultdict(int)
        self.merges = {}

    def fit(self, texts):
        # Count the frequency of each character
        for text in texts:
            for char in text:
                self.vocab[char] += 1

        # Merge the most common character pairs
        for i in range(self.num_merges):
            pair_freq = defaultdict(int)

            for text in texts:
                pairs = [text[j:j+2] for j in range(len(text)-1)]
                for pair in pairs:
                    pair_freq[pair] += 1

            if not pair_freq:
                break

            top_pair = max(pair_freq, key=pair_freq.get)
            self.merges[top_pair] = len(self.merges) + 1

            for text in texts:
                new_text = []
                i = 0
                while i < len(text):
                    if i == len(text) - 1 or text[i:i+2] != top_pair:
                        new_text.append(text[i])
                        i += 1
                    else:
                        new_text.append(self.merges[top_pair])
                        i += 2

                texts[texts.index(text)] = new_text

    def encode(self, text):
        # Replace character pairs with merge indices
        i = 0
        while i < len(text) - 1:
            pair = text[i:i+2]
            if pair in self.merges:
                text = text[:i] + rlp.encode(self.merges[pair]) + text[i+2:]
                i += len(rlp.encode(self.merges[pair]))
            else:
                i += 1

        return text
```
Note that the encoded text is now in the form of RLP-encoded bytes. To decode the encoded text, you would need to decode the RLP-encoded bytes and then reverse the BPE encoding.


## References:


https://github.com/huggingface/tokenizers


## Videos about use frameworks of transformers

https://www.youtube.com/@SebastienBubeck/videos